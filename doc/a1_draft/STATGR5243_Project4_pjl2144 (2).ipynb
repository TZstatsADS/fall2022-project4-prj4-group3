{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/peter/Downloads/compas-scores-two-years.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function testing environment::\n",
    "def helper_data_cleaning(x):\n",
    "    #This code subsets the dataframe to relevant fields for the purpose of this analysis\n",
    "    df = x[x['race'].isin(['African-American','Caucasian'])]\n",
    "    idx = np.where((df['days_b_screening_arrest']<=30) & (df['days_b_screening_arrest']>=-30) &\n",
    "                   (df['is_recid']!=-1) & (df['c_charge_degree']!=\"O\") & (df['score_text']!=\"N/A\") &\n",
    "                   ((df['race']==\"African-American\") |(df['race']==\"Caucasian\")))\n",
    "    df = df.iloc[idx]\n",
    "    df=df.filter(items=['raw_data', 'age', 'c_charge_degree', 'race', 'age_cat', 'score_text', 'sex', 'priors_count', \n",
    "                    'days_b_screening_arrest', 'decile_score', 'is_recid', 'two_year_recid', 'c_jail_in', 'c_jail_out'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def encoding_data(x):\n",
    "    \n",
    "    x['race'] = x['race'].apply(lambda x: 1 if x == \"Caucasian\" else 0)\n",
    "    #print(x['race'])\n",
    "    x['sex'] = x['sex'].apply(lambda x: 1 if x == \"Female\" else 0)\n",
    "    \n",
    "    df1 = x\n",
    "    df1['length_of_stay']=df1['c_jail_out'].apply(pd.to_datetime) - df1['c_jail_in'].apply(pd.to_datetime)\n",
    "    df1['length_of_stay']=df1['length_of_stay'].dt.days\n",
    "    df1['length_of_stay'] = df1.length_of_stay.apply(lambda x: 2  if x >100 else (1 if x >10 else 0))\n",
    "    df1['priors_count'] = df1['priors_count'].apply(lambda x: 0 if x == 0 else x)\n",
    "    df1['priors_count'] = df1['priors_count'].apply(lambda x: 1 if (1 <= x <= 3) else x)\n",
    "    df1['priors_count'] = df1['priors_count'].apply(lambda x: 2 if x > 3 else x)\n",
    "    # Label Encoding \n",
    "    #df1['race'] = df1['race'].apply(lambda x: 1 if x == 'Caucasian' else 0, axis = 0)\n",
    "    #df1['race'] = df1['race_2']\n",
    "    #df1.loc[df1.race=='Caucasian']=1\n",
    "    #df1.loc[df1.race=='African-American']=0\n",
    "\n",
    "    categorical_variables = ['c_charge_degree','sex','age_cat','score_text','length_of_stay','race']\n",
    "    for var in categorical_variables:\n",
    "        df1[var] = df1[var].astype('category').cat.codes\n",
    "    final_vars = ['sex','age_cat','race','priors_count','c_charge_degree','length_of_stay']\n",
    "    df1 = df1[final_vars]\n",
    "    y = x['two_year_recid']\n",
    "    return y,df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning/prepping data\n",
    "df_1 = helper_data_cleaning(df)\n",
    "y, df_1 = encoding_data(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_information_coef(x, y):\n",
    "    import itertools\n",
    "    nrow = x.shape[0]\n",
    "    x_shap = x.shape[1]\n",
    "    z = np.concatenate((x,y), axis=1)\n",
    "    \n",
    "    #unique combinations of possible encodings\n",
    "    unique_combo = []\n",
    "    for r in z.T:\n",
    "        unique_combo.append(np.unique(r).tolist())\n",
    "    \n",
    "    cartesian = list(itertools.product(*unique_combo))\n",
    "    \n",
    "    running_p = 0\n",
    "    \n",
    "    \n",
    "    for possible in cartesian:\n",
    "        #print(ff,\" \", possible)\n",
    "        mutual_ct, r_1_ct, r_2_ct = 0,0,0\n",
    "        mutual_ct = np.sum(np.all(possible == z, axis=1))\n",
    "        r_1_ct = np.sum(np.all(possible[:x_shap] == z[:,:x_shap], axis=1))\n",
    "        r_2_ct = np.sum(np.all(possible[x_shap:] == z[:,x_shap:], axis=1))\n",
    "        \n",
    "        #for row in z:\n",
    "            #checking if joint\n",
    "         #   if possible == row:\n",
    "          #      mutual_ct = mutual_ct+1 \n",
    "            #checking x\n",
    "           # if possible[:x_shap]== z[:x_shap]:\n",
    "            #    r_1_ct = r_1_ct +1\n",
    "            #checking y\n",
    "            #if possible[x_shap:]== z[x_shap:]:\n",
    "             #   r_2_ct = r_2_ct +1\n",
    "            \n",
    "        \n",
    "        #saving computation in the event there's a zero result\n",
    "        if (mutual_ct == 0 or r_1_ct == 0 or r_2_ct == 0):\n",
    "            intermed = 0\n",
    "        else:\n",
    "            mutual_p = mutual_ct/nrow\n",
    "            pr1 = r_1_ct/nrow\n",
    "            pr2 = r_2_ct/nrow\n",
    "            intermed = mutual_p * np.log(mutual_p / pr1) / pr1\n",
    "        running_p += abs(intermed)\n",
    "        \n",
    "        \n",
    "    return running_p\n",
    "\n",
    "def conditional_info_coef(x,y,c):\n",
    "    import itertools\n",
    "    nrow = x.shape[0]\n",
    "    x_shap = x.shape[1]\n",
    "    y_shap = y.shape[1]\n",
    "    #print(x.shape,y.shape,c.shape)\n",
    "    z = np.concatenate((y,x,c), axis=1)\n",
    "    \n",
    "    #unique combinations of possible encodings\n",
    "    unique_combo = []\n",
    "    for r in z.T:\n",
    "        unique_combo.append(np.unique(r).tolist())\n",
    "    \n",
    "    cartesian = list(itertools.product(*unique_combo))\n",
    "    \n",
    "    running_p = 0\n",
    "    \n",
    "    \n",
    "    for possible in cartesian:\n",
    "        \n",
    "        #print(ff,\" \", possible)\n",
    "        mutual_ct, r_1_ct, r_2_ct, r_cond = 0,0,0,0\n",
    "        mutual_ct = np.sum(np.all(possible == z, axis=1))\n",
    "        # r_1_ct = np.sum(np.all(possible[:1] == z[:,:1], axis=1))\n",
    "        # r_2_ct = np.sum(np.all(possible[1:-x_shap] == z[:,1:-x_shap], axis=1))\n",
    "        r_1_ct = np.sum(np.all(possible[:y_shap] == z[:,:y_shap], axis=1))\n",
    "        r_2_ct = np.sum(np.all(possible[y_shap:-x_shap] == z[:,y_shap:-x_shap], axis=1))\n",
    "        cond_ct_num = np.sum(np.where((possible[:y_shap] == z[:,:y_shap]).all(axis=1) & (possible[-x_shap:] == z[:,-x_shap:]).all(axis=1)))\n",
    "        cond_ct_den = np.sum(np.where((possible[-x_shap:] == z[:,-x_shap:]).all(axis=1)))\n",
    "        if cond_ct_den == 0:\n",
    "            r_cond = 0\n",
    "        else:\n",
    "            r_cond = cond_ct_num/cond_ct_den\n",
    "        #for row in z:\n",
    "            #checking if joint\n",
    "         #   if possible == row:\n",
    "          #      mutual_ct = mutual_ct+1 \n",
    "            #checking x\n",
    "           # if possible[:x_shap]== z[:x_shap]:\n",
    "            #    r_1_ct = r_1_ct +1\n",
    "            #checking y\n",
    "            #if possible[x_shap:]== z[x_shap:]:\n",
    "             #   r_2_ct = r_2_ct +1\n",
    "            \n",
    "        \n",
    "        #saving computation in the event there's a zero result\n",
    "        if (mutual_ct == 0 or r_1_ct == 0 or r_2_ct == 0 or r_cond ==0):\n",
    "            intermed = 0\n",
    "        else:\n",
    "            mutual_p = mutual_ct/nrow\n",
    "            pr1 = r_1_ct/nrow\n",
    "            pr2 = r_2_ct/nrow\n",
    "            intermed = mutual_p * np.log(mutual_p / pr2) / r_cond\n",
    "    \n",
    "        running_p += abs(intermed)\n",
    "        \n",
    "        \n",
    "    return running_p\n",
    "\n",
    "def powerset(seq):\n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "        yield []\n",
    "    else:\n",
    "        for item in powerset(seq[1:]):\n",
    "            yield [seq[0]]+item\n",
    "            yield item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MY SHAPELY DISCRIMINATION\n",
    "def shapelydiscrimination(x,y):\n",
    "    \n",
    "    features = list(x.columns)\n",
    "    features = [ele for ele in features if ele != 'race'] #removing race from list of features over which we iterate\n",
    "    nfeat = len(features)\n",
    "    \n",
    "    shapely_coeff = []\n",
    "    \n",
    "    #identifying a feature sequentially to exclude from infoset calc\n",
    "    for i in range(nfeat):\n",
    "        \n",
    "        features_2 = features.copy()\n",
    "        rem = features_2.pop(i) #removing a feature i programmatically\n",
    "        pow_set = [elm for elm in powerset(features_2)] #generating powerset list of lists\n",
    "        \n",
    "        shapely_inter = 0 #for summing the shapelys\n",
    "        #now, iterating over the subsets\n",
    "        for subset in pow_set:\n",
    "            s_len = len(subset)\n",
    "            f_len = nfeat - 1 - len(subset)\n",
    "            \n",
    "            m_coefficient = math.factorial(s_len) * math.factorial(f_len) / math.factorial(nfeat) #coeff\n",
    "            \n",
    "            #inclusive discrimination metric\n",
    "            inc_sub = subset.copy()\n",
    "            inc_sub.append(rem)\n",
    "            \n",
    "            x_1 = np.array(x[inc_sub])\n",
    "            #print(\"x:\",)\n",
    "            protected_attribute = np.array(x['race']).reshape(-1,1)\n",
    "            #print(protected_attribute.shape)\n",
    "            y_1 = np.array(y).reshape(-1,1)\n",
    "            \n",
    "            info_in_ = np.concatenate((x_1,protected_attribute), axis = 1)\n",
    "            \n",
    "            incl_a = unique_information_coef(info_in_,y_1)\n",
    "            incl_b = unique_information_coef(x_1,protected_attribute)\n",
    "            incl_c = conditional_info_coef(x_1,protected_attribute,y_1)\n",
    "            \n",
    "            incl = incl_a * incl_b * incl_c\n",
    "            #call info right here\n",
    "            \n",
    "            #exclusive discrimination metric\n",
    "            x_2 = np.array(x[subset])\n",
    "            info_ex_ = np.concatenate((x_2,protected_attribute), axis = 1)\n",
    "            excl_a = unique_information_coef(info_ex_,y_1)\n",
    "            excl_b = unique_information_coef(x_2,protected_attribute)\n",
    "            excl_c = conditional_info_coef(x_2,protected_attribute,y_1)\n",
    "            excl = excl_a * excl_b * excl_c\n",
    "            \n",
    "            #call info right here\n",
    "            marginal_discrimination = incl-excl\n",
    "            #marginal = disc_incl - disc_excl\n",
    "            #shapley_coeff[i] = shapley_coeff[i] + coef * marginal\n",
    "            shapely_inter = shapely_inter + m_coefficient * marginal_discrimination\n",
    "        shapely_coeff.append(shapely_inter)\n",
    "       \n",
    "    return shapely_coeff\n",
    "\n",
    "def shapelyaccuracy(x,y):\n",
    "    features = list(x.columns)\n",
    "    features = [ele for ele in features if ele != 'race'] #removing race from list of features over which we iterate\n",
    "    nfeat = len(features)\n",
    "    \n",
    "    shapely_coeff = []\n",
    "    \n",
    "    #identifying a feature sequentially to exclude from infoset calc\n",
    "    for i in range(nfeat):\n",
    "        \n",
    "        features_2 = features.copy()\n",
    "        rem = features_2.pop(i) #removing a feature i programmatically\n",
    "        pow_set = [elm for elm in powerset(features_2)] #generating powerset list of lists\n",
    "        \n",
    "        shapely_inter = 0 #for summing the shapelys\n",
    "        #now, iterating over the subsets\n",
    "        for subset in pow_set:\n",
    "            s_len = len(subset)\n",
    "            f_len = nfeat - 1 - len(subset)\n",
    "            \n",
    "            m_coefficient = math.factorial(s_len) * math.factorial(f_len) / math.factorial(nfeat) #coeff\n",
    "            \n",
    "            #inclusive accuracy metric\n",
    "            inc_sub = subset.copy()\n",
    "            inc_sub.append(rem)\n",
    "            inc_sub_diff = list(set(features)-set(inc_sub))\n",
    "            x_1c = np.array(x[inc_sub_diff])\n",
    "            x_1 = np.array(x[inc_sub])\n",
    "            #print(\"x:\",)\n",
    "            protected_attribute = np.array(x['race']).reshape(-1,1)\n",
    "            #print(protected_attribute.shape)\n",
    "            y_1 = np.array(y).reshape(-1,1)\n",
    "            \n",
    "            c = np.concatenate((x_1c,protected_attribute), axis = 1)\n",
    "            \n",
    "            #print( \"out2: \",get_conditional_info_coef(y_1,x_1,c))\n",
    "            accuracy_inclusive = conditional_info_coef(x_1,y_1,c)\n",
    "            #call info right here\n",
    "            \n",
    "            #exclusive accuracy metric\n",
    "            x_2 = np.array(x[subset])\n",
    "            excl_sub = features_2\n",
    "            excl_sub_diff = list(set(features_2)-set(subset))\n",
    "            x_2c = np.array(x[excl_sub_diff])\n",
    "            d = np.concatenate((x_2c,protected_attribute), axis = 1)\n",
    "            accuracy_exclusive = conditional_info_coef(x_2,y_1,d)\n",
    "            \n",
    "            #marginal accuracy by including\n",
    "            marginal_acc = accuracy_inclusive - accuracy_exclusive\n",
    "            shapely_inter = shapely_inter + m_coefficient * marginal_acc\n",
    "            \n",
    "        if shapely_inter> 0:\n",
    "            shapely_coeff.append(shapely_inter)\n",
    "    return shapely_coeff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.397212982177734\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "accuracy = shapelyaccuracy(df_1,y)\n",
    "discrimination = shapelydiscrimination(df_1,y)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'age_cat', 'race', 'priors_count', 'c_charge_degree',\n",
       "       'length_of_stay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(df_1.columns)\n",
    "features = [ele for ele in features if ele != 'race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_disc_pretty = pd.DataFrame(list(zip(features,accuracy,discrimination)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_disc_pretty.columns = ['variable','accuracy','discrimination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          variable  accuracy  discrimination\n",
      "0              sex  0.664604     5933.746182\n",
      "1          age_cat  0.974554     8871.607730\n",
      "2     priors_count  0.967169     9024.280430\n",
      "3  c_charge_degree  0.780089     7155.980280\n",
      "4   length_of_stay  0.732485     8352.821957\n"
     ]
    }
   ],
   "source": [
    "print(acc_disc_pretty)\n",
    "varlist_for_model = list(acc_disc_pretty['variable'])\n",
    "varlist_for_model.remove('priors_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'age_cat', 'c_charge_degree', 'length_of_stay']\n"
     ]
    }
   ],
   "source": [
    "print(varlist_for_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.5555555555555556 Train Accuracy:  0.5709258256632377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peter/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/peter/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n",
      "/Users/peter/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:283: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "df_m = df_1[varlist_for_model]\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_m, y, test_size=0.3, random_state=1,shuffle=True)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "y_hat = model.predict(x_test)\n",
    "test_acc = accuracy_score(y_hat,y_test)\n",
    "y_hat_train = model.predict(x_train)\n",
    "train_acc = accuracy_score(y_hat_train,y_train)\n",
    "print(\"Test Accuracy: \",test_acc,\"Train Accuracy: \",train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.merge(x_train, df_1, left_index=True, right_index=True)\n",
    "x_train['pred'] = y_hat_train\n",
    "x_train['act'] = y_train\n",
    "x_test = pd.merge(x_test, df_1, left_index=True, right_index=True)\n",
    "x_test['pred'] = y_hat\n",
    "x_test['act'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_c = x_train[x_train['race'] == 1]\n",
    "x_test_c = x_test[x_test['race'] == 1]\n",
    "x_train_nc = x_train[x_train['race'] == 0]\n",
    "x_test_nc = x_test[x_test['race'] == 0]\n",
    "White_train_acc = accuracy_score(x_train_c['pred'],x_train_c['act'])\n",
    "Black_train_acc = accuracy_score(x_train_nc['pred'],x_train_nc['act'])\n",
    "white_test_acc = accuracy_score(x_test_c['pred'],x_test_c['act'])\n",
    "Black_test_acc = accuracy_score(x_test_nc['pred'],x_test_nc['act'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White train accuracy:  0.5740868366643694\n",
      "Black train accuracy:  0.5688809629959876\n",
      "White test accuracy:  0.5782208588957055\n",
      "Black test accuracy:  0.5396995708154506\n"
     ]
    }
   ],
   "source": [
    "print(\"White train accuracy: \", White_train_acc)\n",
    "print(\"Black train accuracy: \", Black_train_acc)\n",
    "print(\"White test accuracy: \", white_test_acc)\n",
    "print(\"Black test accuracy: \", Black_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(x_test['act'],x_test['pred']).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative:  598  True Positive:  282  False Negative:  432 False Positive:  272\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negative: \",tn,\" True Positive: \",tp,\" False Negative: \", fn,\"False Positive: \",fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
