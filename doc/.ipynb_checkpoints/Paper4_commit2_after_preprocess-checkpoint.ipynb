{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2sjcLSz68ivk",
   "metadata": {
    "id": "2sjcLSz68ivk"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.optimize as optim\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import feature_extraction\n",
    "import os,sys\n",
    "from random import seed, shuffle\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import numpy.core.multiarray\n",
    "import cvxpy as cvx\n",
    "import dccp\n",
    "from dccp.problem import is_dccp\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8b41740",
   "metadata": {
    "id": "d8b41740",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_dm = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28e3c19a",
   "metadata": {
    "id": "28e3c19a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('compas-scores-two-years.csv')\n",
    "df['length_of_stay']=df['c_jail_out'].apply(pd.to_datetime) - df['c_jail_in'].apply(pd.to_datetime)\n",
    "df['length_of_stay']=df['length_of_stay'].dt.days\n",
    "df['length_of_stay'] = df.length_of_stay.apply(lambda x:'greater than 100 days'  if x >100 else ('10-100 days' if x >10 else 'less than 10 days'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "GBSFLqTn8Mat",
   "metadata": {
    "id": "GBSFLqTn8Mat"
   },
   "outputs": [],
   "source": [
    "#Selecting features\n",
    "features = [\"age_cat\", \"race\", \"sex\", \"priors_count\", \"c_charge_degree\",\"length_of_stay\",\"decile_score\"] \n",
    "cont_feature = [\"priors_count\"] \n",
    "sensitive_attrs = [\"race\"]\n",
    "\n",
    "x_control = defaultdict(list)\n",
    "data=df.copy()\n",
    "\n",
    "# Data Filtering\n",
    "idx = np.where((data['days_b_screening_arrest']<=30) & (data['days_b_screening_arrest']>=-30)\n",
    " & (data['is_recid']!=-1) & (data['c_charge_degree']!=\"O\") & (data['score_text']!=\"N/A\") &\n",
    " ((data['race']==\"African-American\") |(data['race']==\"Caucasian\")))\n",
    "data=data.iloc[idx]\n",
    "\n",
    "\n",
    "# convert class label 0 to -1\n",
    "y = data['two_year_recid']\n",
    "y[y==0] = -1\n",
    "\n",
    "#adding intercept\n",
    "intercept = np.ones(data.shape[0]).reshape(data.shape[0], 1)\n",
    "X=pd.DataFrame(intercept, columns=['intercept'])\n",
    "\n",
    "\n",
    "feature_names = []\n",
    "for attr in features:\n",
    "    vals = data[attr]\n",
    "    if attr in cont_feature:\n",
    "        vals = [float(v) for v in vals]\n",
    "        vals = preprocessing.scale(vals) #makes it into a 0 mean and variance 1\n",
    "        vals = np.reshape(vals, (len(y), -1))\n",
    "      \n",
    "    else: \n",
    "        lb = preprocessing.LabelBinarizer()\n",
    "        lb.fit(vals)\n",
    "        vals = lb.transform(vals)\n",
    "\n",
    "   \n",
    "# Creating list called feature_names which contains column names\n",
    "    # Checking continuous features\n",
    "    if attr in cont_feature: \n",
    "        feature_names.append(attr)\n",
    "    #Checking categorical features\n",
    "    else: \n",
    "        # Binary features\n",
    "        if vals.shape[1] == 1: \n",
    "            feature_names.append(attr)\n",
    "        #Non Binary features - adding the names for every category\n",
    "        else:\n",
    "            for k in lb.classes_: \n",
    "                feature_names.append(attr + \"_\" + str(k))\n",
    "    \n",
    "    X[feature_names]=vals\n",
    "    feature_names=[]\n",
    "\n",
    "\n",
    "    \n",
    "# Splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1,shuffle=True)\n",
    "x_control_train=x_train[sensitive_attrs]\n",
    "x_control_test =x_test[sensitive_attrs]\n",
    "feature_names= x_train.columns\n",
    "x_train,x_test, y_train, y_test,x_control_train,x_control_test=x_train.values,x_test.values, y_train.values, y_test.values,x_control_train.values,x_control_test.values#converting everything to an array\n",
    "\n",
    "#Making x_control_train and x_control_test into a dictionary \n",
    "x_control_train={sensitive_attrs[0]:x_control_train.flatten()}\n",
    "x_control_test={sensitive_attrs[0]:x_control_test.flatten()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f19607f4",
   "metadata": {
    "id": "f19607f4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_one_hot_encoding(in_arr):\n",
    "        \n",
    "    in_arr = np.array(in_arr, dtype=int)\n",
    "    assert(len(in_arr.shape)==1) # no column, means it was a 1-D arr\n",
    "    attr_vals_uniq_sorted = sorted(list(set(in_arr)))\n",
    "    num_uniq_vals = len(attr_vals_uniq_sorted)\n",
    "    if (num_uniq_vals == 2) and (attr_vals_uniq_sorted[0] == 0 and attr_vals_uniq_sorted[1] == 1):\n",
    "        return in_arr, None\n",
    "\n",
    "    \n",
    "    index_dict = {} # value to the column number\n",
    "    for i in range(0,len(attr_vals_uniq_sorted)):\n",
    "        val = attr_vals_uniq_sorted[i]\n",
    "        index_dict[val] = i\n",
    "\n",
    "    out_arr = []    \n",
    "    for i in range(0,len(in_arr)):\n",
    "        tup = np.zeros(num_uniq_vals)\n",
    "        val = in_arr[i]\n",
    "        ind = index_dict[val]\n",
    "        tup[ind] = 1 # set that value of tuple to 1\n",
    "        out_arr.append(tup)\n",
    "\n",
    "    return np.array(out_arr), index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b4ac7a9",
   "metadata": {
    "id": "5b4ac7a9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model_disp_mist(x, y, x_control, EPS, cons_params,tau, mu):\n",
    "\n",
    "    max_iters = 100 \n",
    "    max_iter_dccp = 50  \n",
    "\n",
    "    num_points, num_features = x.shape\n",
    "    w = cvx.Variable(num_features) \n",
    "    np.random.seed(0)\n",
    "    w.value = np.random.rand(x.shape[1])\n",
    "    loss = cvx.sum(  cvx.logistic( cvx.multiply(-y, x*w) )  ) / num_points # Using Logistic Classifier\n",
    "    constraints = []\n",
    "    if cons_params is not None: # just train a simple classifier, no fairness constraints\n",
    " \n",
    "        for attr in cons_params[\"sensitive_attrs_to_cov_thresh\"].keys():\n",
    "\n",
    "            attr_arr = x_control_train[attr]\n",
    "            attr_arr_transformed, index_dict = get_one_hot_encoding(attr_arr)\n",
    "\n",
    "            s_val_to_total = {ct:{} for ct in [0,1,2]} # constrain type -> sens_attr_val -> total number\n",
    "            s_val_to_avg = {ct:{} for ct in [0,1,2]}\n",
    "            cons_sum_dict = {ct:{} for ct in [0,1,2]} # sum of entities (females and males) in constraints are stored here\n",
    "\n",
    "            for v in set(attr_arr):\n",
    "                s_val_to_total[0][v] = sum(x_control_train[attr] == v)\n",
    "                s_val_to_total[1][v] = sum(np.logical_and(x_control_train[attr] == v, y_train == -1)) # FPR constraint so we only consider the ground truth negative dataset for computing the covariance\n",
    "                s_val_to_total[2][v] = sum(np.logical_and(x_control_train[attr] == v, y_train == +1))\n",
    "\n",
    "\n",
    "            for ct in [0,1,2]:\n",
    "                s_val_to_avg[ct][0] = s_val_to_total[ct][1] / float(s_val_to_total[ct][0] + s_val_to_total[ct][1]) # N1/N in our formulation, differs from one constraint type to another\n",
    "                s_val_to_avg[ct][1] = 1.0 - s_val_to_avg[ct][0] # N0/N\n",
    "\n",
    "\n",
    "            for v in set(attr_arr):\n",
    "\n",
    "                idx = x_control_train[attr] == v                \n",
    "\n",
    "\n",
    "                #################################################################\n",
    "                # #DCCP constraints\n",
    "                dist_bound_prod = cvx.multiply(y_train[idx], x_train[idx] * w) # y.f(x)\n",
    "\n",
    "                cons_sum_dict[0][v] = cvx.sum( cvx.minimum(0, dist_bound_prod) ) * (s_val_to_avg[0][v] / len(x_train)) # avg misclassification distance from boundary\n",
    "                cons_sum_dict[1][v] = cvx.sum( cvx.minimum(0, cvx.multiply( (1 - y_train[idx])/2.0, dist_bound_prod) ) ) * (s_val_to_avg[1][v] / sum(y_train == -1)) # avg false positive distance from boundary (only operates on the ground truth neg dataset)\n",
    "                cons_sum_dict[2][v] = cvx.sum( cvx.minimum(0, cvx.multiply( (1 + y_train[idx])/2.0, dist_bound_prod) ) ) * (s_val_to_avg[2][v] / sum(y_train == +1)) # avg false negative distance from boundary\n",
    "                #################################################################\n",
    "\n",
    "\n",
    "            if cons_params[\"cons_type\"] == 4:\n",
    "                cts = [1,2]\n",
    "            elif cons_params[\"cons_type\"] in [0,1,2]:\n",
    "                cts = [cons_params[\"cons_type\"]]\n",
    "\n",
    "            else:\n",
    "                raise Exception(\"Invalid constraint type\")\n",
    "\n",
    "\n",
    "            #################################################################\n",
    "            #DCCP constraints\n",
    "            for ct in cts:\n",
    "                thresh = abs(cons_params[\"sensitive_attrs_to_cov_thresh\"][attr][ct][1] - cons_params[\"sensitive_attrs_to_cov_thresh\"][attr][ct][0])\n",
    "                constraints.append( cons_sum_dict[ct][1] <= cons_sum_dict[ct][0]  + thresh )\n",
    "                constraints.append( cons_sum_dict[ct][1] >= cons_sum_dict[ct][0]  - thresh )\n",
    "\n",
    "            #################################################################\n",
    "        \n",
    "    if cons_params is not None:\n",
    "        if cons_params.get(\"take_initial_sol\") is None: # true by default\n",
    "            take_initial_sol = True\n",
    "        elif cons_params[\"take_initial_sol\"] == False:\n",
    "            take_initial_sol = False\n",
    "\n",
    "        if take_initial_sol == True: # get the initial solution\n",
    "            p = cvx.Problem(cvx.Minimize(loss), [])\n",
    "            p.solve()\n",
    "    prob = cvx.Problem(cvx.Minimize(loss), constraints)\n",
    "    \n",
    "    try:\n",
    "\n",
    "         # default dccp parameters, need to be varied per dataset\n",
    "        if cons_params is not None: # in case we passed these parameters as a part of dccp constraints\n",
    "            if cons_params.get(\"tau\") is not None: tau = cons_params[\"tau\"]\n",
    "            if cons_params.get(\"mu\") is not None: mu = cons_params[\"mu\"]\n",
    "\n",
    "        prob.solve(method='dccp', tau=tau, mu=mu, tau_max=1e10,\n",
    "            solver='ECOS', verbose=False, \n",
    "            feastol=EPS, abstol=EPS, reltol=EPS,feastol_inacc=EPS, abstol_inacc=EPS, reltol_inacc=EPS,\n",
    "            max_iters=max_iters, max_iter=max_iter_dccp)\n",
    "\n",
    "        \n",
    "        assert(prob.status == \"Converged\" or prob.status == \"optimal\")\n",
    "        # print \"Optimization done, problem status:\", prob.status\n",
    "\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        sys.stdout.flush()\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    # check that the fairness constraint is satisfied\n",
    "    for f_c in constraints:\n",
    "       # assert(f_c.value == True) # can comment this out if the solver fails too often, but make sure that the constraints are satisfied empirically. alternatively, consider increasing tau parameter\n",
    "        pass\n",
    "        \n",
    "\n",
    "    w = np.array(w.value).flatten() # flatten converts it to a 1d array\n",
    "\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0ceed61",
   "metadata": {
    "id": "d0ceed61",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_fpr_fnr_sensitive_features(y_true, y_pred, x_control, sensitive_attrs, verbose = False):\n",
    "\n",
    "\n",
    "\n",
    "    # we will make some changes to x_control in this function, so make a copy in order to preserve the origianl referenced object\n",
    "    x_control_internal = deepcopy(x_control)\n",
    "\n",
    "    s_attr_to_fp_fn = {}\n",
    "    \n",
    "    for s in sensitive_attrs:\n",
    "        s_attr_to_fp_fn[s] = {}\n",
    "        s_attr_vals = x_control_internal[s]\n",
    "        if verbose == True:\n",
    "            print( \"||  s  || FPR. || FNR. ||\")\n",
    "        for s_val in sorted(list(set(s_attr_vals))):\n",
    "            s_attr_to_fp_fn[s][s_val] = {}\n",
    "            y_true_local = y_true[s_attr_vals==s_val]\n",
    "            y_pred_local = y_pred[s_attr_vals==s_val]\n",
    "\n",
    "            \n",
    "\n",
    "            acc = float(sum(y_true_local==y_pred_local)) / len(y_true_local)\n",
    "\n",
    "            fp = sum(np.logical_and(y_true_local == -1.0, y_pred_local == +1.0)) # something which is -ve but is misclassified as +ve\n",
    "            fn = sum(np.logical_and(y_true_local == +1.0, y_pred_local == -1.0)) # something which is +ve but is misclassified as -ve\n",
    "            tp = sum(np.logical_and(y_true_local == +1.0, y_pred_local == +1.0)) # something which is +ve AND is correctly classified as +ve\n",
    "            tn = sum(np.logical_and(y_true_local == -1.0, y_pred_local == -1.0)) # something which is -ve AND is correctly classified as -ve\n",
    "\n",
    "            all_neg = sum(y_true_local == -1.0)\n",
    "            all_pos = sum(y_true_local == +1.0)\n",
    "\n",
    "            fpr = float(fp) / float(fp + tn)\n",
    "            fnr = float(fn) / float(fn + tp)\n",
    "            tpr = float(tp) / float(tp + fn)\n",
    "            tnr = float(tn) / float(tn + fp)\n",
    "\n",
    "\n",
    "            s_attr_to_fp_fn[s][s_val][\"fp\"] = fp\n",
    "            s_attr_to_fp_fn[s][s_val][\"fn\"] = fn\n",
    "            s_attr_to_fp_fn[s][s_val][\"fpr\"] = fpr\n",
    "            s_attr_to_fp_fn[s][s_val][\"fnr\"] = fnr\n",
    "\n",
    "            s_attr_to_fp_fn[s][s_val][\"acc\"] = (tp + tn) / (tp + tn + fp + fn)\n",
    "            if verbose == True:\n",
    "                if isinstance(s_val, float): # print the int value of the sensitive attr val\n",
    "                    s_val = int(s_val)\n",
    "                print (\"||  %s  || %0.2f || %0.2f ||\" % (s_val, fpr, fnr))\n",
    "\n",
    "        \n",
    "        return s_attr_to_fp_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f9bc627",
   "metadata": {
    "id": "5f9bc627",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_sensitive_attr_constraint_fpr_fnr_cov(model, x_arr, y_arr_true, y_arr_dist_boundary, x_control_arr, verbose=False):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we compute the covariance between sensitive attr val and ONLY misclassification distances from boundary for False-positives\n",
    "    (-N_1 / N) sum_0(min(0, y.f(x))) + (N_0 / N) sum_1(min(0, y.f(x))) for all misclassifications\n",
    "    (-N_1 / N) sum_0(min(0, (1-y)/2 . y.f(x))) + (N_0 / N) sum_1(min(0,  (1-y)/2. y.f(x))) for FPR\n",
    "    y_arr_true are the true class labels\n",
    "    y_arr_dist_boundary are the predicted distances from the decision boundary\n",
    "    If the model is None, we assume that the y_arr_dist_boundary contains the distace from the decision boundary\n",
    "    If the model is not None, we just compute a dot product or model and x_arr\n",
    "    for the case of SVM, we pass the distace from bounday becase the intercept in internalized for the class\n",
    "    and we have compute the distance using the project function\n",
    "    this function will return -1 if the constraint specified by thresh parameter is not satifsified\n",
    "    otherwise it will reutrn +1\n",
    "    if the return value is >=0, then the constraint is satisfied\n",
    "    \"\"\"\n",
    "\n",
    "        \n",
    "    assert(x_arr.shape[0] == x_control_arr.shape[0])\n",
    "    if len(x_control_arr.shape) > 1: # make sure we just have one column in the array\n",
    "        assert(x_control_arr.shape[1] == 1)\n",
    "    if len(set(x_control_arr)) != 2: # non binary attr\n",
    "        raise Exception(\"Non binary attr, fix to handle non bin attrs\")\n",
    "\n",
    "    \n",
    "    arr = []\n",
    "    if model is None:\n",
    "        arr = y_arr_dist_boundary * y_arr_true # simply the output labels\n",
    "    else:\n",
    "        arr = np.dot(model, x_arr.T) * y_arr_true # the product with the weight vector -- the sign of this is the output label\n",
    "    arr = np.array(arr)\n",
    "\n",
    "    s_val_to_total = {ct:{} for ct in [0,1,2]}\n",
    "    s_val_to_avg = {ct:{} for ct in [0,1,2]}\n",
    "    cons_sum_dict = {ct:{} for ct in [0,1,2]} # sum of entities (females and males) in constraints are stored here\n",
    "\n",
    "    for v in set(x_control_arr):\n",
    "        s_val_to_total[0][v] = sum(x_control_arr == v)\n",
    "        s_val_to_total[1][v] = sum(np.logical_and(x_control_arr == v, y_arr_true == -1))\n",
    "        s_val_to_total[2][v] = sum(np.logical_and(x_control_arr == v, y_arr_true == +1))\n",
    "\n",
    "\n",
    "    for ct in [0,1,2]:\n",
    "        s_val_to_avg[ct][0] = s_val_to_total[ct][1] / float(s_val_to_total[ct][0] + s_val_to_total[ct][1]) # N1 / N\n",
    "        s_val_to_avg[ct][1] = 1.0 - s_val_to_avg[ct][0] # N0 / N\n",
    "\n",
    "    \n",
    "    for v in set(x_control_arr):\n",
    "        idx = x_control_arr == v\n",
    "        dist_bound_prod = arr[idx]\n",
    "\n",
    "        cons_sum_dict[0][v] = sum( np.minimum(0, dist_bound_prod) ) * (s_val_to_avg[0][v] / len(x_arr))\n",
    "        cons_sum_dict[1][v] = sum( np.minimum(0, ( (1 - y_arr_true[idx]) / 2 ) * dist_bound_prod) ) * (s_val_to_avg[1][v] / sum(y_arr_true == -1))\n",
    "        cons_sum_dict[2][v] = sum( np.minimum(0, ( (1 + y_arr_true[idx]) / 2 ) * dist_bound_prod) ) * (s_val_to_avg[2][v] / sum(y_arr_true == +1))\n",
    "        \n",
    "\n",
    "    cons_type_to_name = {0:\"ALL\", 1:\"FPR\", 2:\"FNR\"}\n",
    "    for cons_type in [0,1,2]:\n",
    "        cov_type_name = cons_type_to_name[cons_type]    \n",
    "        cov = cons_sum_dict[cons_type][1] - cons_sum_dict[cons_type][0]\n",
    "        if verbose == True:\n",
    "            print( \"Covariance for type '%s' is: %0.7f\" %(cov_type_name, cov))\n",
    "        \n",
    "    return cons_sum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d5d6377",
   "metadata": {
    "id": "9d5d6377",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_accuracy(model, x_train, y_train, x_test, y_test, y_train_predicted, y_test_predicted):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    returns the train/test accuracy of the model\n",
    "    we either pass the model (w)\n",
    "    else we pass y_predicted\n",
    "    \"\"\"\n",
    "    if model is not None and y_test_predicted is not None:\n",
    "        print (\"Either the model (w) or the predicted labels should be None\")\n",
    "        raise Exception(\"Either the model (w) or the predicted labels should be None\")\n",
    "\n",
    "    if model is not None:\n",
    "        y_test_predicted = np.sign(np.dot(x_test, model))\n",
    "        y_train_predicted = np.sign(np.dot(x_train, model))\n",
    "\n",
    "    def get_accuracy(y, Y_predicted):\n",
    "        correct_answers = (Y_predicted == y).astype(int) # will have 1 when the prediction and the actual label match\n",
    "        accuracy = float(sum(correct_answers)) / float(len(correct_answers))\n",
    "        return accuracy, sum(correct_answers)\n",
    "\n",
    "    train_score, correct_answers_train = get_accuracy(y_train, y_train_predicted)\n",
    "    test_score, correct_answers_test = get_accuracy(y_test, y_test_predicted)\n",
    "\n",
    "    return train_score, test_score, correct_answers_train, correct_answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54ebec4d",
   "metadata": {
    "id": "54ebec4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_distance_boundary(w, x, s_attr_arr):\n",
    "\n",
    "    \"\"\"\n",
    "        if we have boundaries per group, then use those separate boundaries for each sensitive group\n",
    "        else, use the same weight vector for everything\n",
    "    \"\"\"\n",
    "\n",
    "    distances_boundary = np.zeros(x.shape[0])\n",
    "    if isinstance(w, dict): # if we have separate weight vectors per group\n",
    "        for k in w.keys(): # for each w corresponding to each sensitive group\n",
    "            d = np.dot(x, w[k])\n",
    "            distances_boundary[s_attr_arr == k] = d[s_attr_arr == k] # set this distance only for people with this sensitive attr val\n",
    "    else: # we just learn one w for everyone else\n",
    "        distances_boundary = np.dot(x, w)\n",
    "    return distances_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bfef571",
   "metadata": {
    "id": "4bfef571",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_clf_stats(w, x_train, y_train, x_control_train, x_test, y_test, x_control_test, sensitive_attrs):\n",
    "\n",
    "    \n",
    "    assert(len(sensitive_attrs) == 1) # ensure that we have just one sensitive attribute\n",
    "    s_attr = \"race\" # for now, lets compute the accuracy for just one sensitive attr\n",
    "    #s_attr = sensitive_attrs[0] # for now, lets compute the accuracy for just one sensitive attr\n",
    "\n",
    "\n",
    "    # compute distance from boundary\n",
    "    distances_boundary_train = get_distance_boundary(w, x_train, x_control_train[s_attr])\n",
    "    distances_boundary_test = get_distance_boundary(w, x_test, x_control_test[s_attr])\n",
    "\n",
    "    # compute the class labels\n",
    "    all_class_labels_assigned_train = np.sign(distances_boundary_train)\n",
    "    all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "\n",
    "\n",
    "    train_score, test_score, correct_answers_train, correct_answers_test = check_accuracy(None, x_train, y_train, x_test, y_test, all_class_labels_assigned_train, all_class_labels_assigned_test)\n",
    "\n",
    "    \n",
    "    cov_all_train = {}\n",
    "    cov_all_test = {}\n",
    "    for s_attr in sensitive_attrs:\n",
    "        \n",
    "        \n",
    "        print_stats = False # we arent printing the stats for the train set to avoid clutter\n",
    "\n",
    "        # uncomment these lines to print stats for the train fold\n",
    "        # print \"*** Train ***\"\n",
    "        # print \"Accuracy: %0.3f\" % (train_score)\n",
    "        # print_stats = True\n",
    "        s_attr_to_fp_fn_train = get_fpr_fnr_sensitive_features(y_train, all_class_labels_assigned_train, x_control_train, sensitive_attrs, print_stats)\n",
    "        cov_all_train[s_attr] = get_sensitive_attr_constraint_fpr_fnr_cov(None, x_train, y_train, distances_boundary_train, x_control_train[s_attr]) \n",
    "        \n",
    "\n",
    "        print (\"\\n\")\n",
    "        print( \"Accuracy: %0.3f\" % (test_score))\n",
    "        print_stats = True # only print stats for the test fold\n",
    "        s_attr_to_fp_fn_test = get_fpr_fnr_sensitive_features(y_test, all_class_labels_assigned_test, x_control_test, sensitive_attrs, print_stats)\n",
    "        cov_all_test[s_attr] = get_sensitive_attr_constraint_fpr_fnr_cov(None, x_test, y_test, distances_boundary_test, x_control_test[s_attr]) \n",
    "        print (\"\\n\")\n",
    "\n",
    "    return train_score, test_score, cov_all_train, cov_all_test, s_attr_to_fp_fn_train, s_attr_to_fp_fn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "569aa202",
   "metadata": {
    "id": "569aa202",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test_classifier(EPS,tau,mu,cons_params):\n",
    "    \n",
    "    w = train_model_disp_mist(x_train, y_train, x_control_train, EPS, cons_params,tau, mu)\n",
    "\n",
    "    \n",
    "    train_score, test_score, cov_all_train, cov_all_test, s_attr_to_fp_fn_train, s_attr_to_fp_fn_test = get_clf_stats(w, x_train, y_train, x_control_train, x_test, y_test, x_control_test, sensitive_attrs)\n",
    "\n",
    "    # accuracy and FPR are for the test because we need of for plotting\n",
    "    return w, test_score, s_attr_to_fp_fn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f213e745",
   "metadata": {
    "id": "f213e745",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def return_accuracy_1(threshold):\n",
    "    \"\"\" Classify the data while optimizing for accuracy \"\"\"\n",
    "    print(\"== Unconstrained (original) classifier ==\")\n",
    "    EPS = 1e-6\n",
    "    cons_type = 0 # FPR constraint -- just change the cons_type, the rest of parameters should stay the same\n",
    "    tau = 5.0\n",
    "    mu = 1.2\n",
    "    sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:threshold}, 1:{0:0, 1:0}, 2:{0:0, 1:0}}} # zero covariance threshold, means try to get the fairest solution\n",
    "    cons_params = {\"cons_type\": cons_type, \"tau\": tau, \"mu\": mu, \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "    w_uncons, acc_uncons, s_attr_to_fp_fn_test_uncons = train_test_classifier(EPS,tau,mu,cons_params)\n",
    "    \n",
    "    # print(\"\\n-----------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "098a34cd",
   "metadata": {
    "id": "098a34cd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def return_accuracy_2(threshold):\n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    print(\"\\n\\n== Constraints on FPR ==\") # setting parameter for constraints\n",
    "    EPS = 1e-6\n",
    "    cons_type = 1 # FPR constraint -- just change the cons_type, the rest of parameters should stay the same\n",
    "    tau = 5.0\n",
    "    mu = 1.2\n",
    "    sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:threshold}, 2:{0:0, 1:0}}} # zero covariance threshold, means try to get the fairest solution\n",
    "    cons_params = {\"cons_type\": cons_type, \"tau\": tau, \"mu\": mu, \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "    w_cons, acc_cons, s_attr_to_fp_fn_test_cons  = train_test_classifier(EPS,tau,mu,cons_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd1a91c2",
   "metadata": {
    "id": "cd1a91c2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def return_accuracy_3(threshold):\n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    print(\"\\n\\n== Constraints on FNR ==\") # setting parameter for constraints\n",
    "    EPS = 1e-6\n",
    "    cons_type = 2 # FPR constraint -- just change the cons_type, the rest of parameters should stay the same\n",
    "    tau = 5.0\n",
    "    mu = 1.2\n",
    "    sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:0}, 2:{0:0, 1:threshold}}} # zero covariance threshold, means try to get the fairest solution\n",
    "    cons_params = {\"cons_type\": cons_type, \"tau\": tau, \"mu\": mu, \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "    w_cons, acc_cons, s_attr_to_fp_fn_test_cons  = train_test_classifier(EPS,tau,mu,cons_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcd6a61b",
   "metadata": {
    "id": "bcd6a61b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def return_accuracy_4(threshold):\n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    print(\"\\n\\n== Constraints on FNR & FPR ==\") # setting parameter for constraints\n",
    "    EPS = 1e-6\n",
    "    cons_type = 4 # FPR constraint -- just change the cons_type, the rest of parameters should stay the same\n",
    "    tau = 5.0\n",
    "    mu = 1.2\n",
    "    sensitive_attrs_to_cov_thresh = {\"race\": {0:{0:0, 1:0}, 1:{0:0, 1:threshold}, 2:{0:0, 1:threshold}}} # zero covariance threshold, means try to get the fairest solution\n",
    "    cons_params = {\"cons_type\": cons_type, \"tau\": tau, \"mu\": mu, \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "    w_cons, acc_cons, s_attr_to_fp_fn_test_cons  = train_test_classifier(EPS,tau,mu,cons_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70f1fbea",
   "metadata": {
    "id": "70f1fbea",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bc76b2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bc76b2b",
    "outputId": "4c8ae069-71ba-4ffd-9295-d6dc3e0e4393",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "------------------------\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.662\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.15 || 0.58 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.660\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.30 || 0.39 ||\n",
      "||  1  || 0.27 || 0.44 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.668\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.31 || 0.38 ||\n",
      "||  1  || 0.22 || 0.46 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR & FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.660\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.29 || 0.42 ||\n",
      "||  1  || 0.24 || 0.45 ||\n",
      "\n",
      "\n",
      "------------------------\n",
      "0.01\n",
      "------------------------\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.668\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.34 ||\n",
      "||  1  || 0.27 || 0.42 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.664\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.37 ||\n",
      "||  1  || 0.23 || 0.45 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR & FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.668\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.32 || 0.36 ||\n",
      "||  1  || 0.26 || 0.41 ||\n",
      "\n",
      "\n",
      "------------------------\n",
      "0.015\n",
      "------------------------\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.671\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.34 ||\n",
      "||  1  || 0.23 || 0.44 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.669\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.36 ||\n",
      "||  1  || 0.21 || 0.47 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR & FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.670\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.32 || 0.35 ||\n",
      "||  1  || 0.24 || 0.44 ||\n",
      "\n",
      "\n",
      "------------------------\n",
      "0.02\n",
      "------------------------\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.673\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.34 ||\n",
      "||  1  || 0.21 || 0.47 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.675\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.35 ||\n",
      "||  1  || 0.20 || 0.47 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR & FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.675\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.35 ||\n",
      "||  1  || 0.21 || 0.46 ||\n",
      "\n",
      "\n",
      "------------------------\n",
      "0.025\n",
      "------------------------\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.678\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.34 || 0.33 ||\n",
      "||  1  || 0.17 || 0.50 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.678\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.34 ||\n",
      "||  1  || 0.18 || 0.48 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR & FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.677\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.33 || 0.34 ||\n",
      "||  1  || 0.19 || 0.48 ||\n",
      "\n",
      "\n",
      "------------------------\n",
      "0.03\n",
      "------------------------\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.667\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.36 || 0.33 ||\n",
      "||  1  || 0.16 || 0.55 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.676\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.34 || 0.33 ||\n",
      "||  1  || 0.18 || 0.49 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR & FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.676\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.34 || 0.33 ||\n",
      "||  1  || 0.18 || 0.49 ||\n",
      "\n",
      "\n",
      "------------------------\n",
      "0.035\n",
      "------------------------\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.668\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.38 || 0.31 ||\n",
      "||  1  || 0.15 || 0.57 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.668\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.38 || 0.32 ||\n",
      "||  1  || 0.17 || 0.51 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR & FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.668\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.38 || 0.32 ||\n",
      "||  1  || 0.17 || 0.51 ||\n",
      "\n",
      "\n",
      "------------------------\n",
      "0.04\n",
      "------------------------\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.665\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.38 || 0.32 ||\n",
      "||  1  || 0.17 || 0.52 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR & FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.665\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.38 || 0.32 ||\n",
      "||  1  || 0.17 || 0.52 ||\n",
      "\n",
      "\n",
      "------------------------\n",
      "0.045\n",
      "------------------------\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.31 ||\n",
      "||  1  || 0.16 || 0.55 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR & FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.31 ||\n",
      "||  1  || 0.16 || 0.55 ||\n",
      "\n",
      "\n",
      "------------------------\n",
      "0.05\n",
      "------------------------\n",
      "== Unconstrained (original) classifier ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.666\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.13 || 0.59 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.665\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.15 || 0.57 ||\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "== Constraints on FNR & FPR ==\n",
      "\n",
      "\n",
      "Accuracy: 0.665\n",
      "||  s  || FPR. || FNR. ||\n",
      "||  0  || 0.39 || 0.30 ||\n",
      "||  1  || 0.15 || 0.57 ||\n",
      "\n",
      "\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for threshold in [0,0.01,0.015,0.02,0.025,0.03,0.035,0.04,0.045,0.05]:\n",
    "    print(threshold)\n",
    "    print(\"------------------------\")\n",
    "    return_accuracy_1(threshold)\n",
    "    return_accuracy_2(threshold)\n",
    "    return_accuracy_3(threshold)\n",
    "    return_accuracy_4(threshold)\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cab8fd0",
   "metadata": {
    "id": "2cab8fd0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end_dm = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32feb763",
   "metadata": {
    "id": "32feb763",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runtime_dm = (end_dm-start_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c078b3b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c078b3b1",
    "outputId": "95ead59d-ff82-4786-d3b0-60ceae341289",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime of the complete DM model is 251.9 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f'runtime of the complete DM model is {np.round(runtime_dm, 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3a8cd",
   "metadata": {
    "id": "dba3a8cd",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
