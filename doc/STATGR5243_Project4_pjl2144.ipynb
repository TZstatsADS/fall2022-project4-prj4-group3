{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/peter/Downloads/compas-scores-two-years.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function testing environment::\n",
    "def helper_data_cleaning(x):\n",
    "    #This code subsets the dataframe to relevant fields for the purpose of this analysis\n",
    "    df = x[x['race'].isin(['African-American','Caucasian'])]\n",
    "    idx = np.where((df['days_b_screening_arrest']<=30) & (df['days_b_screening_arrest']>=-30) &\n",
    "                   (df['is_recid']!=-1) & (df['c_charge_degree']!=\"O\") & (df['score_text']!=\"N/A\") &\n",
    "                   ((df['race']==\"African-American\") |(df['race']==\"Caucasian\")))\n",
    "    df = df.iloc[idx]\n",
    "    df=df.filter(items=['raw_data', 'age', 'c_charge_degree', 'race', 'age_cat', 'score_text', 'sex', 'priors_count', \n",
    "                    'days_b_screening_arrest', 'decile_score', 'is_recid', 'two_year_recid', 'c_jail_in', 'c_jail_out'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def encoding_data(x):\n",
    "    \n",
    "    x['race'] = x['race'].apply(lambda x: 1 if x == \"Caucasian\" else 0)\n",
    "    #print(x['race'])\n",
    "    x['sex'] = x['sex'].apply(lambda x: 1 if x == \"Female\" else 0)\n",
    "    \n",
    "    df1 = x\n",
    "    df1['length_of_stay']=df1['c_jail_out'].apply(pd.to_datetime) - df1['c_jail_in'].apply(pd.to_datetime)\n",
    "    df1['length_of_stay']=df1['length_of_stay'].dt.days\n",
    "    df1['length_of_stay'] = df1.length_of_stay.apply(lambda x: 2  if x >100 else (1 if x >10 else 0))\n",
    "    df1['priors_count'] = df1['priors_count'].apply(lambda x: 0 if x == 0 else x)\n",
    "    df1['priors_count'] = df1['priors_count'].apply(lambda x: 1 if (1 <= x <= 3) else x)\n",
    "    df1['priors_count'] = df1['priors_count'].apply(lambda x: 2 if x > 3 else x)\n",
    "    # Label Encoding \n",
    "    #df1['race'] = df1['race'].apply(lambda x: 1 if x == 'Caucasian' else 0, axis = 0)\n",
    "    #df1['race'] = df1['race_2']\n",
    "    #df1.loc[df1.race=='Caucasian']=1\n",
    "    #df1.loc[df1.race=='African-American']=0\n",
    "\n",
    "    categorical_variables = ['c_charge_degree','sex','age_cat','score_text','length_of_stay','race']\n",
    "    for var in categorical_variables:\n",
    "        df1[var] = df1[var].astype('category').cat.codes\n",
    "    final_vars = ['sex','age_cat','race','priors_count','c_charge_degree','length_of_stay']\n",
    "    df1 = df1[final_vars]\n",
    "    y = x['two_year_recid']\n",
    "    return y,df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning/prepping data\n",
    "df_1 = helper_data_cleaning(df)\n",
    "y, df_1 = encoding_data(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_information_coef(x, y):\n",
    "    import itertools\n",
    "    nrow = x.shape[0]\n",
    "    x_shap = x.shape[1]\n",
    "    z = np.concatenate((x,y), axis=1)\n",
    "    \n",
    "    #unique combinations of possible encodings\n",
    "    unique_combo = []\n",
    "    for r in z.T:\n",
    "        unique_combo.append(np.unique(r).tolist())\n",
    "    \n",
    "    cartesian = list(itertools.product(*unique_combo))\n",
    "    \n",
    "    running_p = 0\n",
    "    \n",
    "    \n",
    "    for possible in cartesian:\n",
    "        #print(ff,\" \", possible)\n",
    "        mutual_ct, r_1_ct, r_2_ct = 0,0,0\n",
    "        mutual_ct = np.sum(np.all(possible == z, axis=1))\n",
    "        r_1_ct = np.sum(np.all(possible[:x_shap] == z[:,:x_shap], axis=1))\n",
    "        r_2_ct = np.sum(np.all(possible[x_shap:] == z[:,x_shap:], axis=1))\n",
    "        \n",
    "        #for row in z:\n",
    "            #checking if joint\n",
    "         #   if possible == row:\n",
    "          #      mutual_ct = mutual_ct+1 \n",
    "            #checking x\n",
    "           # if possible[:x_shap]== z[:x_shap]:\n",
    "            #    r_1_ct = r_1_ct +1\n",
    "            #checking y\n",
    "            #if possible[x_shap:]== z[x_shap:]:\n",
    "             #   r_2_ct = r_2_ct +1\n",
    "            \n",
    "        \n",
    "        #saving computation in the event there's a zero result\n",
    "        if (mutual_ct == 0 or r_1_ct == 0 or r_2_ct == 0):\n",
    "            intermed = 0\n",
    "        else:\n",
    "            mutual_p = mutual_ct/nrow\n",
    "            pr1 = r_1_ct/nrow\n",
    "            pr2 = r_2_ct/nrow\n",
    "            intermed = mutual_p * np.log(mutual_p / pr1) / pr1\n",
    "        running_p += abs(intermed)\n",
    "        \n",
    "        \n",
    "    return running_p\n",
    "\n",
    "def conditional_info_coef(x,y,c):\n",
    "    import itertools\n",
    "    nrow = x.shape[0]\n",
    "    x_shap = x.shape[1]\n",
    "    y_shap = y.shape[1]\n",
    "    #print(x.shape,y.shape,c.shape)\n",
    "    z = np.concatenate((y,x,c), axis=1)\n",
    "    \n",
    "    #unique combinations of possible encodings\n",
    "    unique_combo = []\n",
    "    for r in z.T:\n",
    "        unique_combo.append(np.unique(r).tolist())\n",
    "    \n",
    "    cartesian = list(itertools.product(*unique_combo))\n",
    "    \n",
    "    running_p = 0\n",
    "    \n",
    "    \n",
    "    for possible in cartesian:\n",
    "        \n",
    "        #print(ff,\" \", possible)\n",
    "        mutual_ct, r_1_ct, r_2_ct, r_cond = 0,0,0,0\n",
    "        mutual_ct = np.sum(np.all(possible == z, axis=1))\n",
    "        # r_1_ct = np.sum(np.all(possible[:1] == z[:,:1], axis=1))\n",
    "        # r_2_ct = np.sum(np.all(possible[1:-x_shap] == z[:,1:-x_shap], axis=1))\n",
    "        r_1_ct = np.sum(np.all(possible[:y_shap] == z[:,:y_shap], axis=1))\n",
    "        r_2_ct = np.sum(np.all(possible[y_shap:-x_shap] == z[:,y_shap:-x_shap], axis=1))\n",
    "        cond_ct_num = np.sum(np.where((possible[:y_shap] == z[:,:y_shap]).all(axis=1) & (possible[-x_shap:] == z[:,-x_shap:]).all(axis=1)))\n",
    "        cond_ct_den = np.sum(np.where((possible[-x_shap:] == z[:,-x_shap:]).all(axis=1)))\n",
    "        if cond_ct_den == 0:\n",
    "            r_cond = 0\n",
    "        else:\n",
    "            r_cond = cond_ct_num/cond_ct_den\n",
    "        #for row in z:\n",
    "            #checking if joint\n",
    "         #   if possible == row:\n",
    "          #      mutual_ct = mutual_ct+1 \n",
    "            #checking x\n",
    "           # if possible[:x_shap]== z[:x_shap]:\n",
    "            #    r_1_ct = r_1_ct +1\n",
    "            #checking y\n",
    "            #if possible[x_shap:]== z[x_shap:]:\n",
    "             #   r_2_ct = r_2_ct +1\n",
    "            \n",
    "        \n",
    "        #saving computation in the event there's a zero result\n",
    "        if (mutual_ct == 0 or r_1_ct == 0 or r_2_ct == 0 or r_cond ==0):\n",
    "            intermed = 0\n",
    "        else:\n",
    "            mutual_p = mutual_ct/nrow\n",
    "            pr1 = r_1_ct/nrow\n",
    "            pr2 = r_2_ct/nrow\n",
    "            intermed = mutual_p * np.log(mutual_p / pr2) / r_cond\n",
    "    \n",
    "        running_p += abs(intermed)\n",
    "        \n",
    "        \n",
    "    return running_p\n",
    "\n",
    "def powerset(seq):\n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "        yield []\n",
    "    else:\n",
    "        for item in powerset(seq[1:]):\n",
    "            yield [seq[0]]+item\n",
    "            yield item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MY SHAPELY DISCRIMINATION\n",
    "def shapelydiscrimination(x,y):\n",
    "    \n",
    "    features = list(x.columns)\n",
    "    features = [ele for ele in features if ele != 'race'] #removing race from list of features over which we iterate\n",
    "    nfeat = len(features)\n",
    "    \n",
    "    shapely_coeff = []\n",
    "    \n",
    "    #identifying a feature sequentially to exclude from infoset calc\n",
    "    for i in range(nfeat):\n",
    "        \n",
    "        features_2 = features.copy()\n",
    "        rem = features_2.pop(i) #removing a feature i programmatically\n",
    "        pow_set = [elm for elm in powerset(features_2)] #generating powerset list of lists\n",
    "        \n",
    "        shapely_inter = 0 #for summing the shapelys\n",
    "        #now, iterating over the subsets\n",
    "        for subset in pow_set:\n",
    "            s_len = len(subset)\n",
    "            f_len = nfeat - 1 - len(subset)\n",
    "            \n",
    "            m_coefficient = math.factorial(s_len) * math.factorial(f_len) / math.factorial(nfeat) #coeff\n",
    "            \n",
    "            #inclusive discrimination metric\n",
    "            inc_sub = subset.copy()\n",
    "            inc_sub.append(rem)\n",
    "            \n",
    "            x_1 = np.array(x[inc_sub])\n",
    "            #print(\"x:\",)\n",
    "            protected_attribute = np.array(x['race']).reshape(-1,1)\n",
    "            #print(protected_attribute.shape)\n",
    "            y_1 = np.array(y).reshape(-1,1)\n",
    "            \n",
    "            info_in_ = np.concatenate((x_1,protected_attribute), axis = 1)\n",
    "            \n",
    "            incl_a = unique_information_coef(info_in_,y_1)\n",
    "            incl_b = unique_information_coef(x_1,protected_attribute)\n",
    "            incl_c = conditional_info_coef(x_1,protected_attribute,y_1)\n",
    "            \n",
    "            incl = incl_a * incl_b * incl_c\n",
    "            #call info right here\n",
    "            \n",
    "            #exclusive discrimination metric\n",
    "            x_2 = np.array(x[subset])\n",
    "            info_ex_ = np.concatenate((x_2,protected_attribute), axis = 1)\n",
    "            excl_a = unique_information_coef(info_ex_,y_1)\n",
    "            excl_b = unique_information_coef(x_2,protected_attribute)\n",
    "            excl_c = conditional_info_coef(x_2,protected_attribute,y_1)\n",
    "            excl = excl_a * excl_b * excl_c\n",
    "            \n",
    "            #call info right here\n",
    "            marginal_discrimination = incl-excl\n",
    "            #marginal = disc_incl - disc_excl\n",
    "            #shapley_coeff[i] = shapley_coeff[i] + coef * marginal\n",
    "            shapely_inter = shapely_inter + m_coefficient * marginal_discrimination\n",
    "        shapely_coeff.append(shapely_inter)\n",
    "       \n",
    "    return shapely_coeff\n",
    "\n",
    "def shapelyaccuracy(x,y):\n",
    "    features = list(x.columns)\n",
    "    features = [ele for ele in features if ele != 'race'] #removing race from list of features over which we iterate\n",
    "    nfeat = len(features)\n",
    "    \n",
    "    shapely_coeff = []\n",
    "    \n",
    "    #identifying a feature sequentially to exclude from infoset calc\n",
    "    for i in range(nfeat):\n",
    "        \n",
    "        features_2 = features.copy()\n",
    "        rem = features_2.pop(i) #removing a feature i programmatically\n",
    "        pow_set = [elm for elm in powerset(features_2)] #generating powerset list of lists\n",
    "        \n",
    "        shapely_inter = 0 #for summing the shapelys\n",
    "        #now, iterating over the subsets\n",
    "        for subset in pow_set:\n",
    "            s_len = len(subset)\n",
    "            f_len = nfeat - 1 - len(subset)\n",
    "            \n",
    "            m_coefficient = math.factorial(s_len) * math.factorial(f_len) / math.factorial(nfeat) #coeff\n",
    "            \n",
    "            #inclusive accuracy metric\n",
    "            inc_sub = subset.copy()\n",
    "            inc_sub.append(rem)\n",
    "            inc_sub_diff = list(set(features)-set(inc_sub))\n",
    "            x_1c = np.array(x[inc_sub_diff])\n",
    "            x_1 = np.array(x[inc_sub])\n",
    "            #print(\"x:\",)\n",
    "            protected_attribute = np.array(x['race']).reshape(-1,1)\n",
    "            #print(protected_attribute.shape)\n",
    "            y_1 = np.array(y).reshape(-1,1)\n",
    "            \n",
    "            c = np.concatenate((x_1c,protected_attribute), axis = 1)\n",
    "            \n",
    "            #print( \"out2: \",get_conditional_info_coef(y_1,x_1,c))\n",
    "            accuracy_inclusive = conditional_info_coef(x_1,y_1,c)\n",
    "            #call info right here\n",
    "            \n",
    "            #exclusive accuracy metric\n",
    "            x_2 = np.array(x[subset])\n",
    "            excl_sub = features_2\n",
    "            excl_sub_diff = list(set(features_2)-set(subset))\n",
    "            x_2c = np.array(x[excl_sub_diff])\n",
    "            d = np.concatenate((x_2c,protected_attribute), axis = 1)\n",
    "            accuracy_exclusive = conditional_info_coef(x_2,y_1,d)\n",
    "            \n",
    "            #marginal accuracy by including\n",
    "            marginal_acc = accuracy_inclusive - accuracy_exclusive\n",
    "            shapely_inter = shapely_inter + m_coefficient * marginal_acc\n",
    "            \n",
    "        if shapely_inter> 0:\n",
    "            shapely_coeff.append(shapely_inter)\n",
    "    return shapely_coeff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = shapelyaccuracy(df_1,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrimination = shapelydiscrimination(df_1,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'age_cat', 'race', 'priors_count', 'c_charge_degree',\n",
       "       'length_of_stay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(df_1.columns)\n",
    "features = [ele for ele in features if ele != 'race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_disc_pretty = pd.DataFrame(list(zip(features,accuracy,discrimination)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_disc_pretty.columns = ['variable','accuracy','discrimination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>discrimination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.664604</td>\n",
       "      <td>5933.746182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age_cat</td>\n",
       "      <td>0.974554</td>\n",
       "      <td>8871.607730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>priors_count</td>\n",
       "      <td>0.967169</td>\n",
       "      <td>9024.280430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_charge_degree</td>\n",
       "      <td>0.780089</td>\n",
       "      <td>7155.980280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>length_of_stay</td>\n",
       "      <td>0.732485</td>\n",
       "      <td>8352.821957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable  accuracy  discrimination\n",
       "0              sex  0.664604     5933.746182\n",
       "1          age_cat  0.974554     8871.607730\n",
       "2     priors_count  0.967169     9024.280430\n",
       "3  c_charge_degree  0.780089     7155.980280\n",
       "4   length_of_stay  0.732485     8352.821957"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_disc_pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
